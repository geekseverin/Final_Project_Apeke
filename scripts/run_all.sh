#!/bin/bash

# Script principal pour initialiser et dÃ©marrer le cluster Big Data
# Projet Big Data - Traitement DistribuÃ© 2024-2025
# VERSION CORRIGÃ‰E

set -e

echo "ğŸš€ DÃ©marrage du cluster Big Data..."

# Couleurs pour l'affichage
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Fonction pour afficher des messages colorÃ©s
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# Fonction pour attendre qu'un service soit prÃªt (CORRIGÃ‰E)
wait_for_service() {
    local host=$1
    local port=$2
    local service_name=$3
    local max_attempts=60  # 2 minutes
    local attempt=1
    
    log_info "Attente du dÃ©marrage de $service_name sur $host:$port..."
    
    while [ $attempt -le $max_attempts ]; do
        if docker exec hadoop-master bash -c "nc -z $host $port" 2>/dev/null; then
            log_success "$service_name est prÃªt!"
            return 0
        fi
        
        if [ $((attempt % 10)) -eq 0 ]; then
            echo ""
            log_info "Tentative $attempt/$max_attempts pour $service_name..."
        else
            echo -n "."
        fi
        sleep 2
        attempt=$((attempt + 1))
    done
    
    echo ""
    log_error "Timeout: $service_name n'a pas dÃ©marrÃ© dans les temps"
    return 1
}

# Fonction pour vÃ©rifier l'Ã©tat des conteneurs
check_containers() {
    log_info "VÃ©rification de l'Ã©tat des conteneurs..."
    
    local containers=("hadoop-master" "hadoop-worker1" "hadoop-worker2" "hadoop-worker3" "mongodb" "web-app")
    local all_running=true
    
    for container in "${containers[@]}"; do
        if docker ps --format "table {{.Names}}" | grep -q "^${container}$"; then
            log_success "âœ… $container est en cours d'exÃ©cution"
        else
            log_error "âŒ $container n'est pas en cours d'exÃ©cution"
            all_running=false
        fi
    done
    
    if [ "$all_running" = false ]; then
        log_error "Certains conteneurs ne sont pas dÃ©marrÃ©s. Lancez 'docker-compose up -d' d'abord."
        exit 1
    fi
}

# Fonction pour initialiser MongoDB avec plus de robustesse
init_mongodb() {
    log_info "Initialisation des donnÃ©es MongoDB..."
    
    # Attendre que MongoDB soit complÃ¨tement prÃªt
    local mongodb_ready=false
    for i in {1..30}; do
        if docker exec mongodb mongosh --host localhost:27017 --eval "db.runCommand('ping')" 2>/dev/null | grep -q "ok"; then
            mongodb_ready=true
            break
        fi
        echo -n "."
        sleep 2
    done
    
    if [ "$mongodb_ready" = false ]; then
        log_error "MongoDB n'est pas prÃªt aprÃ¨s 1 minute"
        return 1
    fi
    
    echo ""
    log_success "MongoDB est prÃªt"
    
    # ExÃ©cuter le script de population
    if docker exec mongodb /scripts/setup/populate_mongodb.sh; then
        log_success "DonnÃ©es MongoDB initialisÃ©es avec succÃ¨s"
        
        # VÃ©rifier les donnÃ©es
        local sales_count=$(docker exec mongodb mongosh --host localhost:27017 \
            --username admin --password password123 --authenticationDatabase admin \
            --db bigdata --eval "db.sales.countDocuments({})" --quiet 2>/dev/null | tail -n1)
        local customers_count=$(docker exec mongodb mongosh --host localhost:27017 \
            --username admin --password password123 --authenticationDatabase admin \
            --db bigdata --eval "db.customers.countDocuments({})" --quiet 2>/dev/null | tail -n1)
            
        log_info "VÃ©rification des donnÃ©es: $sales_count ventes, $customers_count clients"
        return 0
    else
        log_warning "Erreur lors de l'initialisation MongoDB (peut-Ãªtre dÃ©jÃ  fait)"
        return 1
    fi
}

# Fonction pour crÃ©er les rÃ©pertoires HDFS
setup_hdfs_directories() {
    log_info "Configuration des rÃ©pertoires HDFS..."
    
    local directories=(
        "/user/hadoop/input"
        "/user/hadoop/output" 
        "/data"
        "/pig-data"
        "/pig-output"
        "/spark-output"
        "/spark-logs"
    )
    
    for dir in "${directories[@]}"; do
        log_info "CrÃ©ation du rÃ©pertoire $dir..."
        docker exec hadoop-master hdfs dfs -mkdir -p "$dir" 2>/dev/null || true
        docker exec hadoop-master hdfs dfs -chmod 777 "$dir" 2>/dev/null || true
    done
    
    log_success "RÃ©pertoires HDFS configurÃ©s"
}

# Fonction pour transfÃ©rer les donnÃ©es vers HDFS (CORRIGÃ‰E)
transfer_data_to_hdfs() {
    log_info "Transfert des donnÃ©es MongoDB vers HDFS..."
    
    # VÃ©rifier que MongoDB contient des donnÃ©es
    local sales_count=$(docker exec mongodb mongosh --host localhost:27017 \
        --username admin --password password123 --authenticationDatabase admin \
        --db bigdata --eval "db.sales.countDocuments({})" --quiet 2>/dev/null | tail -n1)
    
    if [ "$sales_count" = "0" ] || [ -z "$sales_count" ]; then
        log_error "Aucune donnÃ©e trouvÃ©e dans MongoDB"
        return 1
    fi
    
    log_info "Export de $sales_count ventes depuis MongoDB..."
    
    # Export depuis MongoDB vers fichiers temporaires
    docker exec mongodb mongoexport --host localhost:27017 \
        --username admin --password password123 --authenticationDatabase admin \
        --db bigdata --collection sales --out /tmp/sales.json --jsonArray
    
    docker exec mongodb mongoexport --host localhost:27017 \
        --username admin --password password123 --authenticationDatabase admin \
        --db bigdata --collection customers --out /tmp/customers.json --jsonArray
    
    # VÃ©rifier que les fichiers ont Ã©tÃ© crÃ©Ã©s
    if ! docker exec mongodb test -s /tmp/sales.json; then
        log_error "Ã‰chec de l'export des ventes"
        return 1
    fi
    
    if ! docker exec mongodb test -s /tmp/customers.json; then
        log_error "Ã‰chec de l'export des clients"
        return 1
    fi
    
    log_info "Export rÃ©ussi, transfert vers HDFS..."
    
    # TransfÃ©rer vers HDFS via pipe
    docker exec mongodb cat /tmp/sales.json | \
        docker exec -i hadoop-master hdfs dfs -put -f - /data/sales.json
    
    docker exec mongodb cat /tmp/customers.json | \
        docker exec -i hadoop-master hdfs dfs -put -f - /data/customers.json
    
    # Nettoyer les fichiers temporaires
    docker exec mongodb rm -f /tmp/sales.json /tmp/customers.json
    
    # VÃ©rifier dans HDFS
    if docker exec hadoop-master hdfs dfs -test -e /data/sales.json && \
       docker exec hadoop-master hdfs dfs -test -e /data/customers.json; then
        log_success "DonnÃ©es transfÃ©rÃ©es vers HDFS avec succÃ¨s"
        
        # Afficher les dÃ©tails
        docker exec hadoop-master hdfs dfs -ls /data/
        return 0
    else
        log_error "Erreur lors du transfert vers HDFS"
        return 1
    fi
}

# Fonction pour exÃ©cuter l'analyse Spark (CORRIGÃ‰E)
run_spark_analysis() {
    log_info "ExÃ©cution de l'analyse Apache Spark..."
    
    # VÃ©rifier que les donnÃ©es existent dans HDFS
    if ! docker exec hadoop-master hdfs dfs -test -e /data/sales.json; then
        log_error "DonnÃ©es sales.json introuvables dans HDFS"
        return 1
    fi
    
    if ! docker exec hadoop-master hdfs dfs -test -e /data/customers.json; then
        log_error "DonnÃ©es customers.json introuvables dans HDFS"
        return 1
    fi
    
    log_info "DonnÃ©es HDFS vÃ©rifiÃ©es, lancement de Spark..."
    
    # ExÃ©cuter le script Spark avec gestion d'erreurs
    if docker exec hadoop-master spark-submit \
        --master local[2] \
        --conf "spark.sql.adaptive.enabled=true" \
        --conf "spark.serializer=org.apache.spark.serializer.KryoSerializer" \
        --driver-memory 1g \
        --executor-memory 1g \
        /scripts/spark/mongodb_reader.py; then
        
        log_success "Analyse Spark terminÃ©e avec succÃ¨s"
        
        # VÃ©rifier les rÃ©sultats
        log_info "VÃ©rification des rÃ©sultats Spark dans HDFS..."
        docker exec hadoop-master hdfs dfs -ls /spark-output/ 2>/dev/null || true
        
        return 0
    else
        log_error "Erreur lors de l'analyse Spark"
        return 1
    fi
}

# Fonction pour exÃ©cuter l'analyse Pig (optionnelle)
run_pig_analysis() {
    log_info "ExÃ©cution de l'analyse Apache Pig..."
    
    if docker exec hadoop-master pig -x local -f /scripts/pig/data_analysis.pig; then
        log_success "Analyse Pig terminÃ©e avec succÃ¨s"
        
        # VÃ©rifier les rÃ©sultats
        log_info "VÃ©rification des rÃ©sultats Pig dans HDFS..."
        docker exec hadoop-master hdfs dfs -ls /pig-output/ 2>/dev/null || true
        
        return 0
    else
        log_warning "Erreur lors de l'analyse Pig (pas critique)"
        return 1
    fi
}

# Fonction principale
main() {
    echo "=" * 80
    echo "ğŸš€ INITIALISATION CLUSTER BIG DATA"
    echo "=" * 80
    
    # 1. VÃ©rifier les conteneurs
    check_containers
    
    # 2. Attendre que les services critiques soient prÃªts
    log_info "Attente des services critiques..."
    wait_for_service hadoop-master 9870 "Hadoop NameNode" || exit 1
    wait_for_service hadoop-master 8088 "Yarn ResourceManager" || exit 1
    wait_for_service hadoop-master 7077 "Spark Master" || exit 1
    wait_for_service mongodb 27017 "MongoDB" || exit 1
    
    # 3. Initialiser MongoDB
    init_mongodb || log_warning "MongoDB peut dÃ©jÃ  Ãªtre initialisÃ©"
    
    # 4. Configurer HDFS
    setup_hdfs_directories
    
    # 5. TransfÃ©rer les donnÃ©es
    if transfer_data_to_hdfs; then
        log_success "Transfert de donnÃ©es rÃ©ussi"
    else
        log_error "Ã‰chec du transfert de donnÃ©es"
        exit 1
    fi
    
    # 6. ExÃ©cuter les analyses
    run_spark_analysis || log_warning "Analyse Spark Ã©chouÃ©e"
    run_pig_analysis || log_warning "Analyse Pig Ã©chouÃ©e"
    
    # 7. RÃ©sumÃ© final
    echo ""
    echo "=" * 80
    echo "ğŸ“Š CLUSTER BIG DATA PRÃŠT"
    echo "=" * 80
    echo "ğŸŒ Hadoop NameNode: http://localhost:9870"
    echo "âš™ï¸  Yarn ResourceManager: http://localhost:8088"  
    echo "âš¡ Spark Master: http://localhost:8080"
    echo "ğŸ“Š Dashboard Web: http://localhost:5000"
    echo "ğŸƒ MongoDB: mongodb://localhost:27017"
    echo "=" * 80
    
    # Afficher l'Ã©tat des conteneurs
    echo ""
    log_info "Ã‰tat des conteneurs:"
    docker-compose ps
    
    echo ""
    log_success "ğŸ‰ Cluster Big Data prÃªt Ã  utiliser!"
    echo ""
    echo "Commandes utiles:"
    echo "  ğŸ” Analyser avec Pig: docker exec hadoop-master pig -f /scripts/pig/data_analysis.pig"
    echo "  âš¡ Analyser avec Spark: docker exec hadoop-master spark-submit /scripts/spark/mongodb_reader.py"
    echo "  ğŸ“ Voir HDFS: docker exec hadoop-master hdfs dfs -ls /"
    echo "  ğŸ›‘ ArrÃªter: docker-compose down -v"
}

# Point d'entrÃ©e
if [ "$1" = "--help" ] || [ "$1" = "-h" ]; then
    echo "Script d'initialisation du cluster Big Data"
    echo ""
    echo "Usage: $0 [options]"
    echo ""
    echo "Options:"
    echo "  -h, --help    Afficher cette aide"
    echo "  --skip-pig    Ignorer l'analyse Pig"
    echo "  --skip-spark  Ignorer l'analyse Spark"
    echo ""
    exit 0
fi

# ExÃ©cuter le script principal
main "$@"
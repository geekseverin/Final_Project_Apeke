#!/bin/bash

# Script principal pour initialiser et d√©marrer le cluster Big Data
# Projet Big Data - Traitement Distribu√© 2024-2025
# VERSION CORRIG√âE

set -e

echo "üöÄ D√©marrage du cluster Big Data..."

# Couleurs pour l'affichage
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Fonction pour afficher des messages color√©s
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# Fonction pour attendre qu'un service soit pr√™t (CORRIG√âE)
wait_for_service() {
    local host=$1
    local port=$2
    local service_name=$3
    local max_attempts=60  # 2 minutes
    local attempt=1
    
    log_info "Attente du d√©marrage de $service_name sur $host:$port..."
    
    while [ $attempt -le $max_attempts ]; do
        if docker exec hadoop-master bash -c "nc -z $host $port" 2>/dev/null; then
            log_success "$service_name est pr√™t!"
            return 0
        fi
        
        if [ $((attempt % 10)) -eq 0 ]; then
            echo ""
            log_info "Tentative $attempt/$max_attempts pour $service_name..."
        else
            echo -n "."
        fi
        sleep 2
        attempt=$((attempt + 1))
    done
    
    echo ""
    log_error "Timeout: $service_name n'a pas d√©marr√© dans les temps"
    return 1
}

# Fonction pour v√©rifier l'√©tat des conteneurs
check_containers() {
    log_info "V√©rification de l'√©tat des conteneurs..."
    
    local containers=("hadoop-master" "hadoop-worker1" "hadoop-worker2" "hadoop-worker3" "mongodb" "web-app")
    local all_running=true
    
    for container in "${containers[@]}"; do
        if docker ps --format "table {{.Names}}" | grep -q "^${container}$"; then
            log_success "‚úÖ $container est en cours d'ex√©cution"
        else
            log_error "‚ùå $container n'est pas en cours d'ex√©cution"
            all_running=false
        fi
    done
    
    if [ "$all_running" = false ]; then
        log_error "Certains conteneurs ne sont pas d√©marr√©s. Lancez 'docker-compose up -d' d'abord."
        exit 1
    fi
}

# Fonction pour initialiser MongoDB avec plus de robustesse
init_mongodb() {
    log_info "Initialisation des donn√©es MongoDB..."
    
    # Attendre que MongoDB soit compl√®tement pr√™t
    local mongodb_ready=false
    for i in {1..30}; do
        if docker exec mongodb mongosh --host localhost:27017 --eval "db.runCommand('ping')" 2>/dev/null | grep -q "ok"; then
            mongodb_ready=true
            break
        fi
        echo -n "."
        sleep 2
    done
    
    if [ "$mongodb_ready" = false ]; then
        log_error "MongoDB n'est pas pr√™t apr√®s 1 minute"
        return 1
    fi
    
    echo ""
    log_success "MongoDB est pr√™t"
    
    # Ex√©cuter le script de population
    if docker exec mongodb /scripts/setup/populate_mongodb.sh; then
        log_success "Donn√©es MongoDB initialis√©es avec succ√®s"
        
        # V√©rifier les donn√©es
        local sales_count=$(docker exec mongodb mongosh --host localhost:27017 \
            --username admin --password password123 --authenticationDatabase admin \
            --db bigdata --eval "db.sales.countDocuments({})" --quiet 2>/dev/null | tail -n1)
        local customers_count=$(docker exec mongodb mongosh --host localhost:27017 \
            --username admin --password password123 --authenticationDatabase admin \
            --db bigdata --eval "db.customers.countDocuments({})" --quiet 2>/dev/null | tail -n1)
            
        log_info "V√©rification des donn√©es: $sales_count ventes, $customers_count clients"
        return 0
    else
        log_warning "Erreur lors de l'initialisation MongoDB (peut-√™tre d√©j√† fait)"
        return 1
    fi
}

# Fonction pour cr√©er les r√©pertoires HDFS
setup_hdfs_directories() {
    log_info "Configuration des r√©pertoires HDFS..."
    
    local directories=(
        "/user/hadoop/input"
        "/user/hadoop/output" 
        "/data"
        "/pig-data"
        "/pig-output"
        "/spark-output"
        "/spark-logs"
    )
    
    for dir in "${directories[@]}"; do
        log_info "Cr√©ation du r√©pertoire $dir..."
        docker exec hadoop-master hdfs dfs -mkdir -p "$dir" 2>/dev/null || true
        docker exec hadoop-master hdfs dfs -chmod 777 "$dir" 2>/dev/null || true
    done
    
    log_success "R√©pertoires HDFS configur√©s"
}

# Fonction pour transf√©rer les donn√©es vers HDFS (CORRIG√âE)
transfer_data_to_hdfs() {
    log_info "Transfert des donn√©es MongoDB vers HDFS..."
    
    # V√©rifier que MongoDB contient des donn√©es
    local sales_count=$(docker exec mongodb mongosh --host localhost:27017 \
        --username admin --password password123 --authenticationDatabase admin \
        --db bigdata --eval "db.sales.countDocuments({})" --quiet 2>/dev/null | tail -n1)
    
    if [ "$sales_count" = "0" ] || [ -z "$sales_count" ]; then
        log_error "Aucune donn√©e trouv√©e dans MongoDB"
        return 1
    fi
    
    log_info "Export de $sales_count ventes depuis MongoDB..."
    
    # Export depuis MongoDB vers fichiers temporaires
    docker exec mongodb mongoexport --host localhost:27017 \
        --username admin --password password123 --authenticationDatabase admin \
        --db bigdata --collection sales --out /tmp/sales.json --jsonArray
    
    docker exec mongodb mongoexport --host localhost:27017 \
        --username admin --password password123 --authenticationDatabase admin \
        --db bigdata --collection customers --out /tmp/customers.json --jsonArray
    
    # V√©rifier que les fichiers ont √©t√© cr√©√©s
    if ! docker exec mongodb test -s /tmp/sales.json; then
        log_error "√âchec de l'export des ventes"
        return 1
    fi
    
    if ! docker exec mongodb test -s /tmp/customers.json; then
        log_error "√âchec de l'export des clients"
        return 1
    fi
    
    log_info "Export r√©ussi, transfert vers HDFS..."
    
    # Transf√©rer vers HDFS via pipe
    docker exec mongodb cat /tmp/sales.json | \
        docker exec -i hadoop-master hdfs dfs -put -f - /data/sales.json
    
    docker exec mongodb cat /tmp/customers.json | \
        docker exec -i hadoop-master hdfs dfs -put -f - /data/customers.json
    
    # Nettoyer les fichiers temporaires
    docker exec mongodb rm -f /tmp/sales.json /tmp/customers.json
    
    # V√©rifier dans HDFS
    if docker exec hadoop-master hdfs dfs -test -e /data/sales.json && \
       docker exec hadoop-master hdfs dfs -test -e /data/customers.json; then
        log_success "Donn√©es transf√©r√©es vers HDFS avec succ√®s"
        
        # Afficher les d√©tails
        docker exec hadoop-master hdfs dfs -ls /data/
        return 0
    else
        log_error "Erreur lors du transfert vers HDFS"
        return 1
    fi
}

# Fonction pour ex√©cuter l'analyse Spark (CORRIG√âE)
run_spark_analysis() {
    log_info "Ex√©cution de l'analyse Apache Spark..."
    
    # V√©rifier que les donn√©es existent dans HDFS
    if ! docker exec hadoop-master hdfs dfs -test -e /data/sales.json; then
        log_error "Donn√©es sales.json introuvables dans HDFS"
        return 1
    fi
    
    if ! docker exec hadoop-master hdfs dfs -test -e /data/customers.json; then
        log_error "Donn√©es customers.json introuvables dans HDFS"
        return 1
    fi
    
    log_info "Donn√©es HDFS v√©rifi√©es, lancement de Spark..."
    
    # Ex√©cuter le script Spark avec gestion d'erreurs
    if docker exec hadoop-master spark-submit \
        --master local[2] \
        --conf "spark.sql.adaptive.enabled=true" \
        --conf "spark.serializer=org.apache.spark.serializer.KryoSerializer" \
        --driver-memory 1g \
        --executor-memory 1g \
        /scripts/spark/mongodb_reader.py; then
        
        log_success "Analyse Spark termin√©e avec succ√®s"
        
        # V√©rifier les r√©sultats
        log_info "V√©rification des r√©sultats Spark dans HDFS..."
        docker exec hadoop-master hdfs dfs -ls /spark-output/ 2>/dev/null || true
        
        return 0
    else
        log_error "Erreur lors de l'analyse Spark"
        return 1
    fi
}

# Fonction pour ex√©cuter l'analyse Pig (optionnelle)
run_pig_analysis() {
    log_info "Ex√©cution de l'analyse Apache Pig..."
    
    if docker exec hadoop-master pig -x local -f /scripts/pig/data_analysis.pig; then
        log_success "Analyse Pig termin√©e avec succ√®s"
        
        # V√©rifier les r√©sultats
        log_info "V√©rification des r√©sultats Pig dans HDFS..."
        docker exec hadoop-master hdfs dfs -ls /pig-output/ 2>/dev/null || true
        
        return 0
    else
        log_warning "Erreur lors de l'analyse Pig (pas critique)"
        return 1
    fi
}

# Fonction principale
main() {
    echo "=" * 80
    echo "üöÄ INITIALISATION CLUSTER BIG DATA"
    echo "=" * 80
    
    # 1. V√©rifier les conteneurs
    check_containers
    
    # 2. Attendre que les services critiques soient pr√™ts
    log_info "Attente des services critiques..."
    wait_for_service hadoop-master 9870 "Hadoop NameNode" || exit 1
    wait_for_service hadoop-master 8088 "Yarn ResourceManager" || exit 1
    wait_for_service hadoop-master 7077 "Spark Master" || exit 1
    wait_for_service mongodb 27017 "MongoDB" || exit 1
    
    # 3. Initialiser MongoDB
    init_mongodb || log_warning "MongoDB peut d√©j√† √™tre initialis√©"
    
    # 4. Configurer HDFS
    setup_hdfs_directories
    
    # 5. Transf√©rer les donn√©es
    if transfer_data_to_hdfs; then
        log_success "Transfert de donn√©es r√©ussi"
    else
        log_error "√âchec du transfert de donn√©es"
        exit 1
    fi
    
    # 6. Ex√©cuter les analyses
    run_spark_analysis || log_warning "Analyse Spark √©chou√©e"
    run_pig_analysis || log_warning "Analyse Pig √©chou√©e"
    
    # 7. R√©sum√© final
    echo ""
    echo "=" * 80
    echo "üìä CLUSTER BIG DATA PR√äT"
    echo "=" * 80
    echo "üåê Hadoop NameNode: http://localhost:9870"
    echo "‚öôÔ∏è  Yarn ResourceManager: http://localhost:8088"  
    echo "‚ö° Spark Master: http://localhost:8080"
    echo "üìä Dashboard Web: http://localhost:5000"
    echo "üçÉ MongoDB: mongodb://localhost:27017"
    echo "=" * 80
    
    # Afficher l'√©tat des conteneurs
    echo ""
    log_info "√âtat des conteneurs:"
    docker-compose ps
    
    echo ""
    log_success "üéâ Cluster Big Data pr√™t √† utiliser!"
    echo ""
    echo "Commandes utiles:"
    echo "  üîç Analyser avec Pig: docker exec hadoop-master pig -f /scripts/pig/data_analysis.pig"
    echo "  ‚ö° Analyser avec Spark: docker exec hadoop-master spark-submit /scripts/spark/mongodb_reader.py"
    echo "  üìÅ Voir HDFS: docker exec hadoop-master hdfs dfs -ls /"
    echo "  üõë Arr√™ter: docker-compose down -v"
}

# Point d'entr√©e
if [ "$1" = "--help" ] || [ "$1" = "-h" ]; then
    echo "Script d'initialisation du cluster Big Data"
    echo ""
    echo "Usage: $0 [options]"
    echo ""
    echo "Options:"
    echo "  -h, --help    Afficher cette aide"
    echo "  --skip-pig    Ignorer l'analyse Pig"
    echo "  --skip-spark  Ignorer l'analyse Spark"
    echo ""
    exit 0
fi

# Ex√©cuter le script principal
main "$@"